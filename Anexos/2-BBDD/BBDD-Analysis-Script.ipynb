{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Structure Analysis and Documentation\n",
    "---\n",
    "\n",
    "**Author:** Miguel Ángel del Rincón Manrique  \n",
    "**Department:** Data Science & Analytics  \n",
    "**Creation Date:** June 21, 2024  \n",
    "**Last Updated:** June 26, 2024  \n",
    "**Version:** 0.7  \n",
    "\n",
    "## Document Information\n",
    "- **Status:** Production\n",
    "- **Classification:** Internal\n",
    "- **Technologies:** Python 3.X, MySQL\n",
    "- **Dependencies:** mysql-connector-python, csv, logging, multiprocessing\n",
    "- **Recommended IDE:** Jupyter Notebook / VS Code\n",
    "\n",
    "## Version Control\n",
    "- v0.1 (06/21/2024): Initial Release\n",
    "  - Basic MySQL database connection\n",
    "  - Simple table and column scanning\n",
    "  - Basic CSV file generation\n",
    "\n",
    "- v0.2 (06/21/2024): Parallel Processing\n",
    "  - Added multiprocessing capabilities\n",
    "  - Process pool implementation\n",
    "  - Performance optimization for large databases\n",
    "\n",
    "- v0.3 (06/24/2024): Encoding Management\n",
    "  - UTF-8 and Latin1 encoding handling\n",
    "  - Special characters cleaning\n",
    "  - Data truncation implementation\n",
    "\n",
    "- v0.4 (06/24/2024): HTML Processing\n",
    "  - HTML entities decoding\n",
    "  - Line break handling\n",
    "  - Special characters management\n",
    "\n",
    "- v0.5 (06/24/2024): Error Management\n",
    "  - Logging system implementation\n",
    "  - Enhanced exception handling\n",
    "  - Error recovery capabilities\n",
    "\n",
    "- v0.6 (06/25/2024): File Processing\n",
    "  - File extension search functionality\n",
    "  - Results filtering\n",
    "  - Specific report generation\n",
    "\n",
    "- v0.7 (06/26/2024): Current Version\n",
    "  - Resume functionality for interrupted scans\n",
    "  - Progress saving implementation\n",
    "  - Checkpoint system\n",
    "\n",
    "## Usage and License\n",
    "This notebook is intended for internal use. All rights reserved.\n",
    "Do not distribute without authorization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This Python script is designed to perform a comprehensive analysis of a MySQL database structure and content. It's particularly useful for database administrators, developers, and data analysts who need to understand, document, or track changes in large and complex database systems. The script offers a range of features to handle various data complexities and provides flexible output options.\n",
    "\n",
    "## Key Features and Functionalities\n",
    "\n",
    "### 1. Database Structure Analysis\n",
    "- Scans all tables and columns in the specified database.\n",
    "- Retrieves detailed information including table names, column names, data types, primary and foreign key relationships.\n",
    "\n",
    "### 2. Data Sampling\n",
    "- For each column, the script retrieves sample data (up to two examples per column).\n",
    "- This feature helps in understanding the actual content stored in each field.\n",
    "\n",
    "### 3. File Extension Filtering\n",
    "- Allows searching for specific file types within text fields.\n",
    "- Useful for identifying columns that might contain links or references to files of particular types (e.g., PDFs, images).\n",
    "\n",
    "### 4. Advanced Data Handling\n",
    "\n",
    "#### a. Encoding Issue Management\n",
    "- Handles potential encoding issues by attempting to decode strings using both 'latin1' and 'utf-8' encodings.\n",
    "- This approach helps in correctly interpreting characters from different language sets.\n",
    "\n",
    "#### b. HTML Entity Unescaping\n",
    "- Unescapes HTML entities found in the data.\n",
    "- Converts HTML encoded characters (like &amp;) back to their original form for better readability.\n",
    "\n",
    "#### c. Newline Handling\n",
    "- Replaces newlines with spaces in data fields.\n",
    "- Ensures that multi-line content doesn't break the structure of the output CSV file.\n",
    "\n",
    "#### d. Value Truncation\n",
    "- Truncates long values to 1000 characters.\n",
    "- Prevents excessively long fields from dominating the output while still providing a substantial sample.\n",
    "\n",
    "### 5. Multiprocessing\n",
    "- Utilizes parallel processing to improve performance, especially beneficial for large databases.\n",
    "\n",
    "### 6. Error Handling and Continuity\n",
    "- Implements robust error handling to continue processing even if issues occur with specific tables or columns.\n",
    "\n",
    "### 7. Resume Capability\n",
    "- Allows for interruption and resumption of long-running scans.\n",
    "- Useful for very large databases where the scan might take a considerable amount of time.\n",
    "\n",
    "### 8. Comparison Feature\n",
    "- Can compare current scan results with previous scans.\n",
    "- Identifies and reports on changes in the database structure or content between scans.\n",
    "\n",
    "### 9. Flexible Output\n",
    "- Generates a comprehensive CSV file containing the database structure and sample data.\n",
    "- When using file extension search, produces an additional CSV file with all matching entries.\n",
    "- Outputs comparison results in a markdown-formatted table, showing added, removed, and modified rows.\n",
    "\n",
    "## Usage in Jupyter Notebook\n",
    "\n",
    "To use this script in a Jupyter Notebook environment, you would typically import the necessary functions and then call them with the required parameters. Here's an example of how you might use it:\n",
    "\n",
    "```python\n",
    "# Import the main function from your script\n",
    "from your_script_name import scan_database\n",
    "\n",
    "# Call the function with the database connection details\n",
    "scan_database(\n",
    "    host='X.X.X.X',\n",
    "    user='user-bewanted',\n",
    "    password='password',\n",
    "    database='production_schema',\n",
    "    compare_file=\"database_structure_production_schema_X.X.X.X_20240626_113856.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/miguelang611/miniconda3/envs/faster-whisper\n",
      "\n",
      "  added / updated specs:\n",
      "    - mysql\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2024.7.2   |       h06a4308_0         127 KB\n",
      "    libcurl-8.7.1              |       h251f7ec_0         424 KB\n",
      "    libssh2-1.11.0             |       h251f7ec_0         282 KB\n",
      "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
      "    mysql-8.4.0                |       h0bac5ae_0        56.6 MB\n",
      "    zstd-1.5.2                 |       ha4553b6_0         488 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        58.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  c-ares             pkgs/main/linux-64::c-ares-1.19.1-h5eee18b_0 \n",
      "  icu                pkgs/main/linux-64::icu-73.1-h6a678d5_0 \n",
      "  krb5               pkgs/main/linux-64::krb5-1.20.1-h143b758_1 \n",
      "  libcurl            pkgs/main/linux-64::libcurl-8.7.1-h251f7ec_0 \n",
      "  libedit            pkgs/main/linux-64::libedit-3.1.20230828-h5eee18b_0 \n",
      "  libev              pkgs/main/linux-64::libev-4.33-h7f8727e_1 \n",
      "  libnghttp2         pkgs/main/linux-64::libnghttp2-1.57.0-h2d74bed_0 \n",
      "  libprotobuf        pkgs/main/linux-64::libprotobuf-3.20.3-he621ea3_0 \n",
      "  libssh2            pkgs/main/linux-64::libssh2-1.11.0-h251f7ec_0 \n",
      "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1 \n",
      "  mysql              pkgs/main/linux-64::mysql-8.4.0-h0bac5ae_0 \n",
      "  zlib               conda-forge/linux-64::zlib-1.2.13-hd590300_5 \n",
      "  zstd               pkgs/main/linux-64::zstd-1.5.2-ha4553b6_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2024.2.2~ --> pkgs/main::ca-certificates-2024.7.2-h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "mysql-8.4.0          | 56.6 MB   |                                       |   0% \n",
      "zstd-1.5.2           | 488 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "lz4-c-1.9.4          | 156 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 127 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "zstd-1.5.2           | 488 KB    | #2                                    |   3% \u001b[A\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    | ##                                    |   6% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | #3                                    |   4% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "lz4-c-1.9.4          | 156 KB    | ###8                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "lz4-c-1.9.4          | 156 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mysql-8.4.0          | 56.6 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "zstd-1.5.2           | 488 KB    | ##################################### | 100% \u001b[A\n",
      "zstd-1.5.2           | 488 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "libcurl-8.7.1        | 424 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2024 | 127 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libssh2-1.11.0       | 282 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - anaconda\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/miguelang611/miniconda3/envs/faster-whisper\n",
      "\n",
      "  added / updated specs:\n",
      "    - mysql-connector-python\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    mysql-common-8.3.0         |       hf1915f5_4         766 KB  conda-forge\n",
      "    mysql-connector-python-8.3.0|  py312hb06c811_0         767 KB  conda-forge\n",
      "    mysql-libs-8.3.0           |       hca2cd23_4         1.5 MB  conda-forge\n",
      "    zstd-1.5.6                 |       ha6fb4c9_0         542 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  mysql-common       conda-forge/linux-64::mysql-common-8.3.0-hf1915f5_4 \n",
      "  mysql-connector-p~ conda-forge/linux-64::mysql-connector-python-8.3.0-py312hb06c811_0 \n",
      "  mysql-libs         conda-forge/linux-64::mysql-libs-8.3.0-hca2cd23_4 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  zstd                     pkgs/main::zstd-1.5.2-ha4553b6_0 --> conda-forge::zstd-1.5.6-ha6fb4c9_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "mysql-libs-8.3.0     | 1.5 MB    |                                       |   0% \n",
      "mysql-connector-pyth | 767 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "mysql-common-8.3.0   | 766 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 542 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "mysql-libs-8.3.0     | 1.5 MB    | 3                                     |   1% \u001b[A\u001b[A\u001b[A\n",
      "mysql-connector-pyth | 767 KB    | 7                                     |   2% \u001b[A\n",
      "\n",
      "mysql-common-8.3.0   | 766 KB    | 7                                     |   2% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "zstd-1.5.6           | 542 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "mysql-libs-8.3.0     | 1.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "mysql-common-8.3.0   | 766 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "mysql-common-8.3.0   | 766 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "mysql-connector-pyth | 767 KB    | ##################################### | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import csv\n",
    "import html\n",
    "import logging\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def connect_db(host, user, password, database):\n",
    "    return mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "\n",
    "def get_tables(cursor, database):\n",
    "    cursor.execute(f\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = '{database}'\")\n",
    "    return [table[0] for table in cursor.fetchall()]\n",
    "\n",
    "def clean_value(value):\n",
    "    if value is None:\n",
    "        return ''\n",
    "    try:\n",
    "        value = str(value).encode('latin1').decode('utf-8')\n",
    "    except:\n",
    "        value = str(value)\n",
    "    value = html.unescape(value)\n",
    "    value = value.replace('\\n', ' ').replace('\\r', '')\n",
    "    return value[:1000] if len(value) > 1000 else value\n",
    "\n",
    "def is_valid_file(filename, search_extensions):\n",
    "    if not search_extensions:\n",
    "        return True\n",
    "    valid_extensions = re.compile(r'.*\\.(' + '|'.join(search_extensions) + ')$', re.IGNORECASE)\n",
    "    return bool(valid_extensions.match(filename))\n",
    "\n",
    "def process_table(table_name, host, user, password, database, search_extensions):\n",
    "    try:\n",
    "        conn = connect_db(host, user, password, database)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT \n",
    "                c.COLUMN_NAME, \n",
    "                c.DATA_TYPE,\n",
    "                c.IS_NULLABLE,\n",
    "                c.COLUMN_KEY,\n",
    "                kcu.REFERENCED_TABLE_NAME,\n",
    "                kcu.REFERENCED_COLUMN_NAME,\n",
    "                c.COLUMN_COMMENT\n",
    "            FROM \n",
    "                INFORMATION_SCHEMA.COLUMNS c\n",
    "            LEFT JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE kcu\n",
    "                ON c.TABLE_SCHEMA = kcu.TABLE_SCHEMA\n",
    "                AND c.TABLE_NAME = kcu.TABLE_NAME\n",
    "                AND c.COLUMN_NAME = kcu.COLUMN_NAME\n",
    "                AND kcu.REFERENCED_TABLE_NAME IS NOT NULL\n",
    "            WHERE \n",
    "                c.TABLE_SCHEMA = '{database}' \n",
    "                AND c.TABLE_NAME = '{table_name}'\n",
    "        \"\"\")\n",
    "        columns = cursor.fetchall()\n",
    "\n",
    "        results = []\n",
    "        all_matches = []\n",
    "        for column in columns:\n",
    "            column_name, data_type, is_nullable, column_key, referenced_table, referenced_column, column_comment = column\n",
    "            is_unique = 'YES' if column_key == 'UNI' else 'NO'\n",
    "            is_primary_key = 'YES' if column_key == 'PRI' else 'NO'\n",
    "            is_foreign_key = 'YES' if referenced_table and referenced_column else 'NO'\n",
    "            referenced_table_column = f\"{referenced_table}.{referenced_column}\" if referenced_table and referenced_column else ''\n",
    "\n",
    "            if search_extensions:\n",
    "                like_conditions = \" OR \".join([f\"`{column_name}` LIKE '%.{ext}%'\" for ext in search_extensions])\n",
    "                query = f\"SELECT `{column_name}` FROM `{table_name}` WHERE {like_conditions}\"\n",
    "            else:\n",
    "                query = f\"SELECT `{column_name}` FROM `{table_name}` LIMIT 2\"\n",
    "\n",
    "            cursor.execute(query)\n",
    "            examples = cursor.fetchall()\n",
    "            \n",
    "            valid_examples = [clean_value(ex[0]) for ex in examples if is_valid_file(str(ex[0]), search_extensions)]\n",
    "            \n",
    "            if search_extensions:\n",
    "                for example in valid_examples:\n",
    "                    all_matches.append([table_name, column_name, example])\n",
    "            \n",
    "            example1 = valid_examples[0] if valid_examples else ''\n",
    "            example2 = valid_examples[1] if len(valid_examples) > 1 else ''\n",
    "\n",
    "            # Generate a description using the available information\n",
    "            description = f\"This column '{column_name}' is of type {data_type}. \"\n",
    "            description += \"It can contain NULL values. \" if is_nullable == 'YES' else \"It cannot contain NULL values. \"\n",
    "            if is_unique == 'YES':\n",
    "                description += \"It has a unique constraint. \"\n",
    "            if is_primary_key == 'YES':\n",
    "                description += \"It is the primary key of the table. \"\n",
    "            if is_foreign_key == 'YES':\n",
    "                description += f\"It is a foreign key referencing {referenced_table_column}. \"\n",
    "            if column_comment:\n",
    "                description += f\"Comment: {column_comment}\"\n",
    "\n",
    "            results.append([\n",
    "                table_name, \n",
    "                column_name, \n",
    "                data_type, \n",
    "                is_nullable,\n",
    "                is_unique,\n",
    "                is_primary_key, \n",
    "                is_foreign_key, \n",
    "                referenced_table_column,\n",
    "                example1,\n",
    "                example2,\n",
    "                description\n",
    "            ])\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return results, all_matches\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing table {table_name}: {str(e)}\")\n",
    "        return [], []\n",
    "\n",
    "def save_all_matches(all_matches, output_file):\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_ALL, escapechar='\\\\', quotechar='\"')\n",
    "        writer.writerow(['Table', 'Column', 'Matching Data'])\n",
    "        writer.writerows(all_matches)\n",
    "    logging.info(f\"All matches saved to '{output_file}'\")\n",
    "\n",
    "def scan_database(host, user, password, database, search_extensions=None, output_file=None, resume_file=None, compare_file=None):\n",
    "    conn = connect_db(host, user, password, database)\n",
    "    cursor = conn.cursor()\n",
    "    tables = get_tables(cursor, database)\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    if not output_file:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"database_structure_{database}_{host}_{timestamp}.csv\"\n",
    "\n",
    "    all_results = []\n",
    "    all_matches = []\n",
    "\n",
    "    if resume_file:\n",
    "        with open(resume_file, 'r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Skip header\n",
    "            all_results = list(reader)\n",
    "        processed_tables = set(row[0] for row in all_results)\n",
    "        tables = [table for table in tables if table not in processed_tables]\n",
    "\n",
    "    num_processes = cpu_count() - 1 or 1\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        process_table_partial = partial(process_table, host=host, user=user, password=password, database=database, search_extensions=search_extensions)\n",
    "        results = pool.map(process_table_partial, tables)\n",
    "\n",
    "    for result, matches in results:\n",
    "        all_results.extend(result)\n",
    "        all_matches.extend(matches)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_ALL, escapechar='\\\\', quotechar='\"')\n",
    "        writer.writerow(['Table', 'Column', 'Data Type', 'Is Nullable', 'Is Unique', 'Is Primary Key', 'Is Foreign Key', 'Referenced Table.Column', 'Example 1', 'Example 2', 'Descripción (Claude)'])\n",
    "        writer.writerows(all_results)\n",
    "\n",
    "    logging.info(f\"CSV file saved as '{output_file}'\")\n",
    "\n",
    "    if search_extensions:\n",
    "        all_matches_file = f\"all_matches_{database}_{host}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        save_all_matches(all_matches, all_matches_file)\n",
    "\n",
    "    if compare_file:\n",
    "        compare_results(compare_file, all_results)\n",
    "\n",
    "def compare_results(old_file, new_results):\n",
    "    with open(old_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header\n",
    "        old_results = list(reader)\n",
    "\n",
    "    old_dict = {(row[0], row[1]): row for row in old_results}\n",
    "    new_dict = {(row[0], row[1]): row for row in new_results}\n",
    "\n",
    "    added = [row for key, row in new_dict.items() if key not in old_dict]\n",
    "    removed = [row for key, row in old_dict.items() if key not in new_dict]\n",
    "    modified = [new_dict[key] for key in old_dict.keys() & new_dict.keys() if old_dict[key] != new_dict[key]]\n",
    "\n",
    "    print(\"\\nAdded rows:\")\n",
    "    print_markdown_table(added)\n",
    "\n",
    "    print(\"\\nRemoved rows:\")\n",
    "    print_markdown_table(removed)\n",
    "\n",
    "    print(\"\\nModified rows:\")\n",
    "    print_markdown_table(modified)\n",
    "\n",
    "def print_markdown_table(results):\n",
    "    headers = [\"Table\", \"Column\", \"Data Type\", \"Is Nullable\", \"Is Unique\", \"Is Primary Key\", \"Is Foreign Key\", \"Referenced Table.Column\", \"Example 1\", \"Example 2\", \"Descripción (Claude)\"]\n",
    "    print(\"| \" + \" | \".join(headers) + \" |\")\n",
    "    print(\"| \" + \" | \".join([\"---\"] * len(headers)) + \" |\")\n",
    "    for row in results:\n",
    "        print(\"| \" + \" | \".join(str(cell) for cell in row) + \" |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the database connection details\n",
    "scan_database(\n",
    "    host='X.X.X.X',\n",
    "    user='user-bewanted',\n",
    "    password='password',\n",
    "    database='production_schema',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
